# Full Docker image reference used by docker-compose (registry/repo:tag).
BOT_IMAGE=ghcr.io/artcc/ollama-telegram-bot:latest

# Name assigned to the running container.
BOT_CONTAINER_NAME=ollama-telegram-bot

# Telegram bot token from @BotFather.
TELEGRAM_BOT_TOKEN=replace_with_telegram_bot_token

# Base URL of your Ollama server (no trailing /v1).
# Example: http://ollama:11434 (same Docker network)
# Example: http://host.docker.internal:11434 (host machine)
OLLAMA_BASE_URL=http://ollama:11434

# Default Ollama model used when user has not selected a custom model.
OLLAMA_DEFAULT_MODEL=llama3.2

# Use Ollama Chat API (/api/chat) as primary path.
# If true, the bot will fallback to /api/generate when chat fails.
OLLAMA_USE_CHAT_API=true

# keep_alive value sent to /api/chat to keep model loaded in memory.
# Examples: 30s, 5m, 1h
OLLAMA_KEEP_ALIVE=5m

# Absolute path inside the container to the SQLite database file.
MODEL_PREFS_DB_PATH=/data/bot.db

# Host path (or named volume mount point) used to persist /data from container.
BOT_DATA_DIR=./data

# REQUIRED: comma-separated numeric Telegram user IDs allowed to use the bot.
# Example: 123456789,987654321
ALLOWED_USER_IDS=123456789

# Application log level (DEBUG, INFO, WARNING, ERROR, CRITICAL).
LOG_LEVEL=INFO

# Timeout in seconds for requests to Ollama API.
REQUEST_TIMEOUT_SECONDS=60

# Number of latest conversation turns kept in memory per user.
MAX_CONTEXT_MESSAGES=12

# Max user messages allowed per window (set > 0 to enable rate limiting).
RATE_LIMIT_MAX_MESSAGES=8

# Sliding window size in seconds used by rate limiting.
RATE_LIMIT_WINDOW_SECONDS=30

# Container timezone (IANA format), used for logs and timestamps.
TZ=Europe/Madrid